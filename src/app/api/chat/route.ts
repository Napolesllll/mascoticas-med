// src/app/api/chat/route.ts
import { NextResponse } from 'next/server';

export async function POST(req: Request) {
  const { messages } = await req.json();

  // Verificar que las messages estÃ©n correctamente formateadas
  if (!Array.isArray(messages) || messages.length === 0) {
    return NextResponse.json({ reply: 'Â¡Ups! No se enviaron mensajes vÃ¡lidos.' }, { status: 400 });
  }

  const lastMessage = messages[messages.length - 1];
  if (lastMessage.role !== 'user') {
    return NextResponse.json({ reply: 'Â¡Lo siento! Solo puedo responder a lo que me diga el usuario.' }, { status: 400 });
  }

  try {
    // AquÃ­ puedes integrar OpenAI o el modelo de chat que estÃ©s usando.
    // Para OpenAI, por ejemplo, algo como:
    // const response = await fetch('https://api.openai.com/v1/chat/completions', { ... });
    
    // Si no estÃ¡s usando OpenAI, podemos simular la respuesta con un mensaje simple:
    const reply = generateBotResponse(lastMessage.content); // FunciÃ³n que genera respuesta

    return NextResponse.json({ reply });

  } catch (error) {
    console.error('Error al generar respuesta del chat:', error);
    return NextResponse.json({ reply: 'Â¡Ups! Algo saliÃ³ mal, por favor intenta de nuevo.' }, { status: 500 });
  }
}

function generateBotResponse(userMessage: string): string {
  // AquÃ­ puedes implementar un sistema bÃ¡sico de respuestas o llamar a un modelo como GPT
  // Respuestas simples como ejemplo
  if (userMessage.toLowerCase().includes('hola')) {
    return 'Â¡Hola! Â¿CÃ³mo estÃ¡s? ğŸ¾';
  }
  if (userMessage.toLowerCase().includes('rutina')) {
    return 'AquÃ­ tienes una rutina recomendada para tu perrito. ğŸ•';
  }
  return 'Max no entendiÃ³ bien. ğŸ¶'; // Respuesta predeterminada
}
